# Using Open-Source Models

We can use Ollama to run open-source models rather than closed Anthropic or OpenAI models like GPT-5.


# Dockering Ollama Server

Running it is pretty easy, but if we want production-grade LLM models running, it is a good idea to containerize our Ollama server as a microservice.